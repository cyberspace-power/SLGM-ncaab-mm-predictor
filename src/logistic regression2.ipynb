{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4194b346",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "061414fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./../Data/Final Data/all_combined.csv\")\n",
    "labels = pd.read_csv(\"./../Data/Final Data/labels.csv\")\n",
    "data['label'] = labels['label']\n",
    "# .set_index([\"teamName\", \"year\"]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "863e550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2514,) (628,)\n",
      "(2514, 13)\n",
      "(628, 13)\n"
     ]
    }
   ],
   "source": [
    "data_0 = data[data['label'] == 0]\n",
    "data_1 = data[data['label'] == 1]\n",
    "\n",
    "# print(data_0)\n",
    "# print(data_1)\n",
    "\n",
    "training_data_0 = data_0.sample(frac=0.8)\n",
    "testing_data_0 = data_0.drop(training_data_0.index)\n",
    "\n",
    "training_data_1 = data_1.sample(frac=0.8)\n",
    "testing_data_1 = data_1.drop(training_data_1.index)\n",
    "\n",
    "# print(\"data class 0\")\n",
    "# print(training_data_0)\n",
    "# print(testing_data_0)\n",
    "\n",
    "# print(\"data class 1\")\n",
    "# print(training_data_1)\n",
    "# print(testing_data_1)\n",
    "\n",
    "X = training_data_0.append(training_data_1, ignore_index=True)\n",
    "# X_train = X.loc[:, X.columns != 'label']\n",
    "X_train = X.loc[:, ~X.columns.isin(['teamName', 'year', 'label', 'NIT', 'R64', 'R32', 'S16', 'E8', 'F4', 'F2', 'CHMP'])]\n",
    "X_label = X['label']\n",
    "\n",
    "# print(\"training\")\n",
    "# print(X)\n",
    "\n",
    "Y = testing_data_0.append(testing_data_1, ignore_index=True)\n",
    "# Y_test = Y.loc[:, Y.columns != 'label']\n",
    "Y_test = Y.loc[:, ~Y.columns.isin(['teamName', 'year', 'label', 'NIT', 'R64', 'R32', 'S16', 'E8', 'F4', 'F2', 'CHMP'])]\n",
    "Y_label = Y['label']\n",
    "print(str(X_label.shape) + \" \" + str(Y_label.shape))\n",
    "\n",
    "# print(\"testing\")\n",
    "# print(Y)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e72574a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           UT Arlington\n",
      "1       Tennessee Martin\n",
      "2         Louisiana Tech\n",
      "3              Weber St.\n",
      "4       Eastern Kentucky\n",
      "              ...       \n",
      "2019             Seattle\n",
      "2020     Bethune Cookman\n",
      "2021      South Carolina\n",
      "2022    Prairie View A&M\n",
      "2023           Milwaukee\n",
      "Name: teamName, Length: 2024, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X[X['label'] == 0].loc[:, 'teamName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a3e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \n",
    "    # set parameters - learning rate, number ot iterations, bias, \n",
    "    # and verbose which says whether to print anything or not like, loss etc.\n",
    "    def __init__(self, learning_rate=0.05, num_iterations=50000, fit_intercept=True, verbose=False):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    # function to define the Incercept value.\n",
    "    def __bias(self, X):\n",
    "        # set bias as 1\n",
    "        bias = np.ones((X.shape[0], 1))\n",
    "        # concat bias to data\n",
    "        return np.concatenate((bias, X), axis=1)\n",
    "    \n",
    "    def __sigmoid_function(self, x):\n",
    "        # sigmoid function to predicts yp\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def __loss(self, yp, y):\n",
    "        # minimize loss\n",
    "        return (-y * np.log(yp) - (1 - y) * np.log(1 - yp)).mean()\n",
    "    \n",
    "    # training function\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # use bias if specified\n",
    "        if self.fit_intercept:\n",
    "            X = self.__bias(X)\n",
    "        \n",
    "        # initialize weights as 0 initially\n",
    "        # self.W = np.zeros(X.shape[1])\n",
    "        self.W = np.random.randn(X.shape[1])  # Randomly generate initial weight matrix with normal distribution (mu=0, sigma = 2)\n",
    "        \n",
    "        # run for number of iterations provided\n",
    "        for i in range(self.num_iterations):\n",
    "            \n",
    "            z = np.dot(X, self.W)\n",
    "            \n",
    "            # prediction probabilities\n",
    "            yp = self.__sigmoid_function(z)\n",
    "            \n",
    "            # calculate gradient\n",
    "            gradient = np.dot(X.T, (yp - y)) / y.size\n",
    "            \n",
    "            # update W\n",
    "            self.W -= self.learning_rate * gradient\n",
    "            \n",
    "            # new W * Xi\n",
    "            z = np.dot(X, self.W)\n",
    "            yp = self.__sigmoid_function(z)\n",
    "            \n",
    "            # calculate loss\n",
    "            if len(yp) == 0 or len(y) == 0:\n",
    "                print(\"Here\")\n",
    "            loss = self.__loss(yp, y)\n",
    "            \n",
    "            # to print loss with verbose\n",
    "            if(self.verbose ==True and i % 1000 == 0):\n",
    "                print(f'loss: {loss} \\t')\n",
    "    \n",
    "    # predict the probabilities using W\n",
    "    def predict_prob(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = self.__bias(X)\n",
    "        \n",
    "        return self.__sigmoid_function(np.dot(X, self.W))\n",
    "    \n",
    "    # predict class from probabilities; less than 0.5 = 0 or more than 0.5 = 1\n",
    "    def predict(self, X):\n",
    "        return self.predict_prob(X).round()\n",
    "    \n",
    "    def set_learning_rate(self, lr):\n",
    "        self.learning_rate = lr\n",
    "        \n",
    "    def set_num_iterations(self, itrs):\n",
    "        self.num_iterations = itrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc3f2007",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(learning_rate=0.05, num_iterations=10000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82138c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7608785775831106 \t\n",
      "loss: 0.3834704718694863 \t\n",
      "loss: 0.37432422295480594 \t\n",
      "loss: 0.3681994854690352 \t\n",
      "loss: 0.36353048782363495 \t\n",
      "loss: 0.35988633130265374 \t\n",
      "loss: 0.3570083947407293 \t\n",
      "loss: 0.354713868730809 \t\n",
      "loss: 0.35286855031536 \t\n",
      "loss: 0.35137225882310613 \t\n",
      "Wall time: 9.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''model.set_learning_rate(0.1)\n",
    "model.set_num_iterations(20000)'''\n",
    "model.fit(X_train, X_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f412cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8710191082802548"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(Y_test)\n",
    "(preds == Y_label).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d21641f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negatives:  492 \n",
      "False positives:  14 \n",
      "False negatives:  67 \n",
      "True Positives:  55\n"
     ]
    }
   ],
   "source": [
    "# Print confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(pd.Series(Y_label), preds).ravel()\n",
    "print('True negatives: ', tn, '\\nFalse positives: ', fp, '\\nFalse negatives: ', fn, '\\nTrue Positives: ', tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f97bd9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------WEIGHTS----------\n",
      "Bias: \t\t\t-3.483991509968205\n",
      "prev_3s_recruits: \t0.018574616257029414\n",
      "prev_4s_recruits: \t0.09009135580145805\n",
      "prev_5s_recruits: \t0.228791631064723\n",
      "curr_3s_recruits: \t-0.03143330160020543\n",
      "curr_4s_recruits: \t0.10022800345748707\n",
      "curr_5s_recruits: \t0.34328940542625\n",
      "seed_points: \t\t0.043193351984931024\n",
      "returningMins%: \t2.091986373417421\n",
      "sos: \t\t\t-0.08345299232679514\n",
      "adjTempo: \t\t0.008912852662272637\n",
      "win ratio: \t\t0.5937985953452354\n",
      "overall efficiency: \t1.1886527750307758\n",
      "stars: \t\t\t0.05829843644520059\n"
     ]
    }
   ],
   "source": [
    "print(\"----------WEIGHTS----------\")\n",
    "print(\"Bias: \\t\\t\\t\" + str(model.W[0]))\n",
    "for i in range(len(X_train.columns)):\n",
    "    if X_train.columns[i] == \"sos\" or X_train.columns[i] == \"stars\" or X_train.columns[i] == \"NIT\":\n",
    "        print(X_train.columns[i] + \": \\t\\t\\t\" + str(model.W[i+1]))\n",
    "    elif X_train.columns[i] == \"adjTempo\" or X_train.columns[i] == \"win ratio\" or X_train.columns[i] == \"seed_points\":\n",
    "        print(X_train.columns[i] + \": \\t\\t\" + str(model.W[i+1]))\n",
    "    else:\n",
    "        print(X_train.columns[i] + \": \\t\" + str(model.W[i+1]))\n",
    "# print(model.W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2ebc77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "clf = LogReg(max_iter = 10000).fit(X_train, X_label)\n",
    "clf.predict(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e94d7274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8742038216560509"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(Y_test, Y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68544401",
   "metadata": {},
   "source": [
    "### SMOTE Oversampling Algorithm for data augmentation to get equally sized classes\n",
    "\n",
    "See the following link: <a>https://towardsdatascience.com/smote-fdce2f605729</a>. Here you will find a description for the SMOTE (Synthetic Minority Oversampling Technique) algorithm, which is useful for oversampling data augmentation. We perform that here using the imbalanced learn python library in order to increase the number of data points labeled as having made the NCAA tournament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4969e144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old X:\tOverall Length = 2514\tNumber of 0 labels = 2024\tNumber of 1 labels = 490\n",
      "New X:\tOverall Length = 4048\tNumber of 0 labels = 2024\tNumber of 1 labels = 2024\n",
      "\n",
      "Old Y:\tOverall Length = 628\tNumber of 0 labels = 506\tNumber of 1 labels = 122\n",
      "New Y:\tOverall Length = 1012\tNumber of 0 labels = 506\tNumber of 1 labels = 506\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Oversample teams who made tournament for training data\n",
    "X_train_resampled, X_label_resampled = SMOTE().fit_resample(X_train, X_label)\n",
    "print(\"Old X:\\tOverall Length = \" + str(len(X_train)) + \"\\tNumber of 0 labels = \" + \n",
    "      str(pd.Series(X_label).value_counts()[0]) + \"\\tNumber of 1 labels = \" + str(pd.Series(X_label).value_counts()[1]))\n",
    "print(\"New X:\\tOverall Length = \" + str(len(X_train_resampled)) + \"\\tNumber of 0 labels = \" + \n",
    "      str(pd.Series(X_label_resampled).value_counts()[0]) + \"\\tNumber of 1 labels = \" + \n",
    "      str(pd.Series(X_label_resampled).value_counts()[1]))\n",
    "\n",
    "# Oversample teams who made tournament for testing data\n",
    "Y_test_resampled, Y_label_resampled = SMOTE().fit_resample(Y_test, Y_label)\n",
    "print(\"\\nOld Y:\\tOverall Length = \" + str(len(Y_test)) + \"\\tNumber of 0 labels = \" + \n",
    "      str(pd.Series(Y_label).value_counts()[0]) + \"\\tNumber of 1 labels = \" + str(pd.Series(Y_label).value_counts()[1]))\n",
    "print(\"New Y:\\tOverall Length = \" + str(len(Y_test_resampled)) + \"\\tNumber of 0 labels = \" + \n",
    "      str(pd.Series(Y_label_resampled).value_counts()[0]) + \"\\tNumber of 1 labels = \" + \n",
    "      str(pd.Series(Y_label_resampled).value_counts()[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3a68ba",
   "metadata": {},
   "source": [
    "##### Now we retrain and retest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4451a997",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.304279059241988 \t\n",
      "loss: 0.49589523974382577 \t\n",
      "loss: 0.4900711862684863 \t\n",
      "loss: 0.4864265326658166 \t\n",
      "loss: 0.48368270280071823 \t\n",
      "loss: 0.48155688079099673 \t\n",
      "loss: 0.479884262606916 \t\n",
      "loss: 0.47855030252855846 \t\n",
      "loss: 0.47747273830815784 \t\n",
      "loss: 0.47659166614529114 \t\n",
      "Wall time: 9.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(learning_rate=0.05, num_iterations=10000, verbose=True)\n",
    "model.fit(X_train_resampled, X_label_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "378030a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7964426877470355"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_preds = model.predict(Y_test_resampled)\n",
    "(new_preds == Y_label_resampled).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2f6fa25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "True negatives:  402 \n",
      "False positives:  104 \n",
      "False negatives:  102 \n",
      "True Positives:  404\n"
     ]
    }
   ],
   "source": [
    "# Print confusion matrix\n",
    "print(str(type(Y_test_resampled)) + \" \" + str(type(new_preds)))\n",
    "tn, fp, fn, tp = confusion_matrix(pd.Series(Y_label_resampled), new_preds).ravel()\n",
    "print('True negatives: ', tn, '\\nFalse positives: ', fp, '\\nFalse negatives: ', fn, '\\nTrue Positives: ', tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58c17d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------WEIGHTS----------\n",
      "Bias: \t\t\t-2.59166378771914\n",
      "prev_3s_recruits: \t-0.08290081284385\n",
      "prev_4s_recruits: \t-0.0019280790313977558\n",
      "prev_5s_recruits: \t0.04027271411977194\n",
      "curr_3s_recruits: \t-0.12346138052173256\n",
      "curr_4s_recruits: \t-0.013801893205736096\n",
      "curr_5s_recruits: \t0.15120226938257658\n",
      "seed_points: \t\t0.06705979949886619\n",
      "returningMins%: \t3.048490648321752\n",
      "sos: \t\t\t0.34312745812487844\n",
      "adjTempo: \t\t0.0547130571711723\n",
      "win ratio: \t\t0.661982399109369\n",
      "overall efficiency: \t1.4023540328881923\n",
      "stars: \t\t\t0.1546210608569627\n"
     ]
    }
   ],
   "source": [
    "print(\"----------WEIGHTS----------\")\n",
    "print(\"Bias: \\t\\t\\t\" + str(model.W[0]))\n",
    "for i in range(len(X_train_resampled.columns)):\n",
    "    if X_train_resampled.columns[i] == \"sos\" or X_train_resampled.columns[i] == \"stars\" or X_train_resampled.columns[i] == \"NIT\":\n",
    "        print(X_train_resampled.columns[i] + \": \\t\\t\\t\" + str(model.W[i+1]))\n",
    "    elif X_train_resampled.columns[i] == \"adjTempo\" or X_train_resampled.columns[i] == \"win ratio\" or X_train_resampled.columns[i] == \"seed_points\":\n",
    "        print(X_train_resampled.columns[i] + \": \\t\\t\" + str(model.W[i+1]))\n",
    "    else:\n",
    "        print(X_train_resampled.columns[i] + \": \\t\" + str(model.W[i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5a5c6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.682806324110672"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_new = LogReg(max_iter = 10000).fit(X_train_resampled, X_label_resampled)\n",
    "clf_new.predict(Y_test_resampled)\n",
    "clf.score(Y_test_resampled, Y_label_resampled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
